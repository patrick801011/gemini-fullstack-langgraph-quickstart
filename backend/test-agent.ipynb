{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import graph\n",
    "\n",
    "state = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Who won the euro 2024\"}], \"max_research_loops\": 3, \"initial_search_query_count\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.invoke({\"messages\": state[\"messages\"] + [{\"role\": \"user\", \"content\": \"How has the most titles? List the top 5\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.src.agent.graph import graph\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from backend.src.agent.configuration import Configuration\n",
    "from langchain_core.messages import HumanMessage\n",
    "from backend.src.agent.traffic_regulations_tool import REGULATIONS_TEXT, TrafficRegulationsRAG\n",
    "import os # For API key check\n",
    "\n",
    "print(\"\\n--- Test: Traffic Regulation Article Query ---\")\n",
    "\n",
    "# Input message for a specific article\n",
    "input_message_article = \"我想查詢道路交通管理處罰條例第3條的內容\"\n",
    "# A simpler query also works due to the regex:\n",
    "# input_message_article = \"道路交通管理處罰條例第3條\" \n",
    "# Even simpler:\n",
    "# input_message_article = \"第3條\" # This should also be caught by the regex\n",
    "\n",
    "# Prepare the initial state for the graph\n",
    "initial_state = {\"messages\": [HumanMessage(content=input_message_article)]}\n",
    "\n",
    "# Configuration\n",
    "# Ensure API keys are set in the environment for the test to run\n",
    "if not os.getenv(\"GEMINI_API_KEY\"):\n",
    "    print(\"GEMINI_API_KEY is not set. Skipping test or it might fail if LLM is hit.\")\n",
    "    # Depending on strictness, you might raise an error or skip:\n",
    "    # raise ValueError(\"GEMINI_API_KEY must be set for this test\") \n",
    "config_runnable = RunnableConfig(configurable=Configuration(number_of_initial_queries=1).get_config()) # Reduced queries for faster test\n",
    "\n",
    "final_result_state = None\n",
    "intermediate_states = []\n",
    "\n",
    "print(f\"Invoking graph with input: {initial_state}\")\n",
    "for event in graph.stream(initial_state, config=config_runnable):\n",
    "    print(f\"Event: {list(event.keys())}\") # Print keys of each event to understand structure\n",
    "    intermediate_states.append(event)\n",
    "    if \"__end__\" in event:\n",
    "        final_result_state = event[\"__end__\"]\n",
    "        break\n",
    "    # Fallback if no __end__ key, take the last event from generate_query or query_traffic_regulations\n",
    "    # This part is tricky without knowing exact event names from the graph stream\n",
    "    # For now, we rely on __end__ or the last event if __end__ is not found.\n",
    "    # A more robust way would be to check for specific node outputs if needed.\n",
    "    # However, the main assertions are on the final AI message and sources.\n",
    "\n",
    "if not final_result_state and intermediate_states:\n",
    "    final_result_state = intermediate_states[-1] # Take the last known event as final state if no __end__\n",
    "\n",
    "# Assert is_traffic_query (indirectly, by checking if RAG was called)\n",
    "# Direct check of is_traffic_query from generate_query's output in the stream:\n",
    "generate_query_output = None\n",
    "for event_data in intermediate_states:\n",
    "    if 'generate_query' in event_data:\n",
    "        generate_query_output = event_data['generate_query']\n",
    "        break\n",
    "\n",
    "assert generate_query_output is not None, \"generate_query node output not found in stream.\"\n",
    "assert generate_query_output.get('is_traffic_query') is True, \"is_traffic_query was not set to True for a traffic query.\"\n",
    "print(\"Test Passed: is_traffic_query was correctly set to True.\")\n",
    "\n",
    "\n",
    "# Fetch the actual Article 3 text from the source for assertion\n",
    "temp_rag = TrafficRegulationsRAG(REGULATIONS_TEXT)\n",
    "# The RAG tool's query method returns the full string including \"找到法規條文：\"\n",
    "article_3_rag_output = temp_rag.query(\"第3條\") \n",
    "article_3_content_for_assertion = \"\"\n",
    "if \"找到法規條文：\" in article_3_rag_output:\n",
    "    # Extract just the content part, similar to how RAG tool structures it\n",
    "    # The RAG output is \"找到法規條文：\\n{title}\\n{content}\"\n",
    "    parts = article_3_rag_output.split(\"\\n\", 2)\n",
    "    if len(parts) > 2:\n",
    "        article_3_content_for_assertion = parts[1] + \"\\n\" + parts[2] # title + content\n",
    "    else: # Fallback if split doesn't work as expected\n",
    "        article_3_content_for_assertion = article_3_rag_output\n",
    "\n",
    "print(f\"Input: {input_message_article}\")\n",
    "\n",
    "ai_message_content = \"\"\n",
    "# The final_result_state should be the state of the graph at the END.\n",
    "# The 'messages' in this state should contain the history, with the last one being from the AI.\n",
    "if final_result_state and final_result_state.get(\"messages\"):\n",
    "    last_message = final_result_state[\"messages\"][-1]\n",
    "    if hasattr(last_message, 'content'):\n",
    "        ai_message_content = last_message.content\n",
    "    elif isinstance(last_message, tuple): # ('ai', 'content')\n",
    "        ai_message_content = last_message[1]\n",
    "    else:\n",
    "        ai_message_content = str(last_message) # Fallback\n",
    "else:\n",
    "    print(\"Warning: Could not determine AI message content from final_result_state.\")\n",
    "    print(f\"Final result state was: {final_result_state}\")\n",
    "\n",
    "\n",
    "print(f\"AI Message Content (first 500 chars): {ai_message_content[:500]}...\")\n",
    "\n",
    "assert article_3_content_for_assertion, \"Article 3 content for assertion could not be prepared.\"\n",
    "# Check if the core content of Article 3 is present.\n",
    "# The finalize_answer node might slightly rephrase or summarize.\n",
    "# A robust check is to see if a significant, unique part of Article 3 is there.\n",
    "# \"本條例用詞，定義如下：\" is the start of Article 3.\n",
    "# \"臨時停車：指車輛因上、下人、客，裝卸物品\" is a unique part of Article 3, item 10.\n",
    "assert \"本條例用詞，定義如下：\" in ai_message_content, \"Article 3 definition start not found in AI response.\"\n",
    "assert \"臨時停車：指車輛因上、下人、客，裝卸物品\" in ai_message_content, \"Key phrase '臨時停車' from Article 3 not found in AI response.\"\n",
    "print(\"Test Passed: Article 3 content is present in the final AI response.\")\n",
    "\n",
    "# Check sources (should be empty for RAG queries routed to finalize_answer without web_research)\n",
    "sources = []\n",
    "if final_result_state:\n",
    "    sources = final_result_state.get(\"sources_gathered\", [])\n",
    "\n",
    "print(f\"Sources gathered: {sources}\")\n",
    "assert not sources, f\"Test Failed: Expected no sources for RAG query, but got {sources}\"\n",
    "print(\"Test Passed: No sources gathered for RAG query, as expected.\")\n",
    "\n",
    "print(\"--- Test: Traffic Regulation Article Query Completed ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 2: Keyword-based Traffic Regulation Query\n",
    "# Ensure necessary imports are available if this cell is run independently\n",
    "# from backend.src.agent.graph import graph\n",
    "# from langchain_core.runnables import RunnableConfig\n",
    "# from backend.src.agent.configuration import Configuration\n",
    "# from langchain_core.messages import HumanMessage\n",
    "# from backend.src.agent.traffic_regulations_tool import REGULATIONS_TEXT, TrafficRegulationsRAG # Might not be needed directly here\n",
    "# import os\n",
    "\n",
    "print(\"\\n--- Test: Keyword-based Traffic Regulation Query ---\")\n",
    "\n",
    "input_message_keyword = \"請問紅燈右轉的罰鍰是多少？\"\n",
    "initial_state_keyword = {\"messages\": [HumanMessage(content=input_message_keyword)]}\n",
    "# Assuming 'config_runnable' is defined from a previous cell or define it here:\n",
    "# if 'config_runnable' not in locals():\n",
    "#     if not os.getenv(\"GEMINI_API_KEY\"):\n",
    "#         print(\"GEMINI_API_KEY is not set. This test might fail if LLM is hit.\")\n",
    "#     config_runnable = RunnableConfig(configurable=Configuration(number_of_initial_queries=1).get_config())\n",
    "\n",
    "final_result_keyword_state = None\n",
    "is_traffic_query_after_gen_keyword = None\n",
    "intermediate_states_keyword = []\n",
    "\n",
    "print(f\"Invoking graph with input: {initial_state_keyword}\")\n",
    "for event in graph.stream(initial_state_keyword, config=config_runnable): # Use config_runnable\n",
    "    #print(f\"Keyword Test Event: {list(event.keys())}\") # For debugging stream\n",
    "    intermediate_states_keyword.append(event)\n",
    "    if \"generate_query\" in event:\n",
    "        is_traffic_query_after_gen_keyword = event[\"generate_query\"].get(\"is_traffic_query\")\n",
    "    if \"__end__\" in event:\n",
    "        final_result_keyword_state = event[\"__end__\"]\n",
    "        break\n",
    "        \n",
    "if not final_result_keyword_state and intermediate_states_keyword:\n",
    "    final_result_keyword_state = intermediate_states_keyword[-1]\n",
    "\n",
    "print(f\"Input: {input_message_keyword}\")\n",
    "print(f\"Is traffic query after generate_query: {is_traffic_query_after_gen_keyword}\")\n",
    "assert is_traffic_query_after_gen_keyword is True, \"Test Failed: Keyword query was not identified as a traffic query.\"\n",
    "print(\"Test Passed: Keyword query correctly identified as a traffic query.\")\n",
    "\n",
    "ai_message_content_keyword = \"\"\n",
    "if final_result_keyword_state and final_result_keyword_state.get(\"messages\"):\n",
    "    last_message = final_result_keyword_state[\"messages\"][-1]\n",
    "    if hasattr(last_message, 'content'):\n",
    "        ai_message_content_keyword = last_message.content\n",
    "    elif isinstance(last_message, tuple):\n",
    "        ai_message_content_keyword = last_message[1]\n",
    "    else:\n",
    "        ai_message_content_keyword = str(last_message)\n",
    "else:\n",
    "    print(f\"Warning: Could not determine AI message content from final_result_keyword_state: {final_result_keyword_state}\")\n",
    "\n",
    "print(f\"AI Message Content (Keyword - first 500 chars): {ai_message_content_keyword[:500]}...\")\n",
    "\n",
    "# Check for content related to Article 53 (fines for running red light / red light right turn)\n",
    "# The RAG tool should find \"第53條\" which details this.\n",
    "# \"汽車駕駛人，行經有燈光號誌管制之交岔路口闖紅燈者，處新臺幣一千八百元以上五千四百元以下罰鍰。\"\n",
    "# \"前項紅燈右轉行為者，處新臺幣六百元以上一千八百元以下罰鍰。\"\n",
    "assert \"第五十三條\" in ai_message_content_keyword or \\\n",
    "       (\"闖紅燈\" in ai_message_content_keyword and \"罰鍰\" in ai_message_content_keyword) or \\\n",
    "       (\"紅燈右轉\" in ai_message_content_keyword and \"罰鍰\" in ai_message_content_keyword and \\\n",
    "        (\"六百元\" in ai_message_content_keyword or \"一千八百元\" in ai_message_content_keyword or \"5400\" in ai_message_content_keyword or \"1800\" in ai_message_content_keyword or \"600\" in ai_message_content_keyword) # Adding numeric checks\n",
    "       ), \\\n",
    "       \"Test Failed: Expected content related to red light right turn fines (Article 53) not found in AI response.\"\n",
    "print(\"Test Passed: Keyword-based traffic query response seems correct.\")\n",
    "\n",
    "sources_keyword = []\n",
    "if final_result_keyword_state:\n",
    "    sources_keyword = final_result_keyword_state.get(\"sources_gathered\", [])\n",
    "    \n",
    "print(f\"Sources gathered (Keyword): {sources_keyword}\")\n",
    "assert not sources_keyword, f\"Test Failed: Expected no sources for RAG query, but got {sources_keyword}\"\n",
    "print(\"Test Passed: No sources gathered for keyword RAG query.\")\n",
    "\n",
    "print(\"--- Test: Keyword-based Traffic Regulation Query Completed ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 3: Non-Traffic (General Web Search) Query\n",
    "print(\"\\n--- Test: Non-Traffic (Web Search) Query ---\")\n",
    "\n",
    "input_message_web = \"今天的台北天氣如何？\"\n",
    "initial_state_web = {\"messages\": [HumanMessage(content=input_message_web)]}\n",
    "# Assuming 'config_runnable' is defined from a previous cell or define it here\n",
    "\n",
    "final_result_web_state = None\n",
    "is_traffic_query_after_gen_web = None\n",
    "web_research_node_output_found = False \n",
    "intermediate_states_web = []\n",
    "\n",
    "print(f\"Invoking graph with input: {initial_state_web}\")\n",
    "for event in graph.stream(initial_state_web, config=config_runnable): # Use config_runnable\n",
    "    #print(f\"Web Test Event: {list(event.keys())}\") # For debugging stream\n",
    "    intermediate_states_web.append(event)\n",
    "    if \"generate_query\" in event:\n",
    "        is_traffic_query_after_gen_web = event[\"generate_query\"].get(\"is_traffic_query\")\n",
    "    # Check if web_research node produced a result. The result is a dict with 'web_research_result'\n",
    "    if \"web_research\" in event and event[\"web_research\"].get(\"web_research_result\"):\n",
    "         web_research_node_output_found = True\n",
    "    if \"__end__\" in event:\n",
    "        final_result_web_state = event[\"__end__\"]\n",
    "        break\n",
    "\n",
    "if not final_result_web_state and intermediate_states_web:\n",
    "    final_result_web_state = intermediate_states_web[-1]\n",
    "\n",
    "\n",
    "print(f\"Input: {input_message_web}\")\n",
    "print(f\"Is traffic query after generate_query: {is_traffic_query_after_gen_web}\")\n",
    "assert is_traffic_query_after_gen_web is False, \"Test Failed: Web query was misidentified as a traffic query.\"\n",
    "print(\"Test Passed: Web query correctly identified as non-traffic.\")\n",
    "\n",
    "ai_message_content_web = \"\"\n",
    "if final_result_web_state and final_result_web_state.get(\"messages\"):\n",
    "    last_message = final_result_web_state[\"messages\"][-1]\n",
    "    if hasattr(last_message, 'content'):\n",
    "        ai_message_content_web = last_message.content\n",
    "    elif isinstance(last_message, tuple):\n",
    "        ai_message_content_web = last_message[1]\n",
    "    else:\n",
    "        ai_message_content_web = str(last_message)\n",
    "else:\n",
    "    print(f\"Warning: Could not determine AI message content from final_result_web_state: {final_result_web_state}\")\n",
    "\n",
    "\n",
    "print(f\"AI Message Content (Web - first 500 chars): {ai_message_content_web[:500]}...\")\n",
    "assert \"天氣\" in ai_message_content_web or \\\n",
    "       \"weather\" in ai_message_content_web.lower() or \\\n",
    "       \"台北\" in ai_message_content_web or \\\n",
    "       \"Taipei\" in ai_message_content_web, \\\n",
    "       \"Test Failed: Expected weather-related content not found in AI response for web query.\"\n",
    "print(\"Test Passed: Web search query response seems correct.\")\n",
    "\n",
    "sources_web = []\n",
    "if final_result_web_state:\n",
    "    sources_web = final_result_web_state.get(\"sources_gathered\", [])\n",
    "\n",
    "print(f\"Sources gathered (Web): {sources_web}\")\n",
    "# For a web query, we expect the web_research node to have been called.\n",
    "# And typically, it should find some sources unless the search is very obscure or fails.\n",
    "assert web_research_node_output_found, \"Test Failed: Web research node does not seem to have produced output for a web query.\"\n",
    "# We can also check if sources_web is populated, but web_research_node_output_found is a more direct check that the node ran.\n",
    "# assert sources_web, \"Test Failed: Expected sources for web query, but got none. (Might be a flaky assertion if web search truly finds nothing).\"\n",
    "print(\"Test Passed: Web research path appears to have been taken and produced output.\")\n",
    "\n",
    "print(\"--- Test: Non-Traffic (Web Search) Query Completed ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
